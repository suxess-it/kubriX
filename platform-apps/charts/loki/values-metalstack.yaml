loki:
  loki:
    commonConfig:
      replication_factor: 1
    auth_enabled: false
    schemaConfig:
      configs:
        - from: 2024-04-01
          store: tsdb
          object_store: s3
          schema: v13
          index:
            prefix: loki_index_
            period: 24h
    ingester:
      chunk_encoding: snappy
    tracing:
      enabled: true
    querier:
      # Default is 4, if you have enough memory and CPU you can increase, reduce if OOMing
      max_concurrent: 4

  gateway:
    ingress:
      enabled: true
      ingressClassName: nginx
      annotations:
        external-dns.alpha.kubernetes.io/ttl: "60"
        cert-manager.io/cluster-issuer: letsencrypt-staging
      hosts:
        - host: logs-monitoring-metalstack.platform-engineer.cloud
          paths:
            - path: /
              pathType: Prefix
      tls:
        - secretName: loki-gateway-tls
          hosts:
            - logs-monitoring-metalstack.platform-engineer.cloud

  deploymentMode: SingleBinary
  singleBinary:
    replicas: 1
    resources:
      limits:
        cpu: 3
        memory: 4Gi
      requests:
        cpu: 2
        memory: 2Gi
    extraEnv:
      # Keep a little bit lower than memory limits
      - name: GOMEMLIMIT
        value: 3750MiB
  
  chunksCache:
    enabled: false
    # default is 500MB, with limited memory keep this smaller
    writebackSizeLimit: 10MB
    allocatedMemory: 2048
  
  # Enable minio for storage
  minio:
    enabled: true
    persistence:
      size: 10Gi

  # Monitoring section determines which monitoring features to enable
  monitoring:
    # Dashboards for monitoring Loki
    dashboards:
      # -- If enabled, create configmap with dashboards for monitoring Loki
      enabled: true
      # -- Annotations for the dashboards ConfigMap
      annotations:
        k8s-sidecar-target-directory: "Loki"
      # -- Labels for the dashboards ConfigMap
      labels:
        grafana_dashboard: "1"
    # Recording rules for monitoring Loki, required for some dashboards
    rules:
      # -- If enabled, create PrometheusRule resource with Loki recording rules
      enabled: true
      # -- Include alerting rules
      alerting: true
      # -- Additional groups to add to the rules file
      additionalGroups:
      - name: additional-loki-rules
        rules:
          - record: job:loki_request_duration_seconds_bucket:sum_rate
            expr: sum(rate(loki_request_duration_seconds_bucket[1m])) by (le, job)
          - record: job_route:loki_request_duration_seconds_bucket:sum_rate
            expr: sum(rate(loki_request_duration_seconds_bucket[1m])) by (le, job, route)
          - record: node_namespace_pod_container:container_cpu_usage_seconds_total:sum_rate
            expr: sum(rate(container_cpu_usage_seconds_total[1m])) by (node, namespace, pod, container)
    # ServiceMonitor configuration
    serviceMonitor:
      # -- If enabled, ServiceMonitor resources for Prometheus Operator are created
      enabled: true
      # -- ServiceMonitor scrape interval
      # Default is 15s because included recording rules use a 1m rate, and scrape interval needs to be at
      # least 1/4 rate interval.
      interval: 15s
      # -- ServiceMonitor relabel configs to apply to samples before scraping
      # https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#relabelconfig
      relabelings:
        - sourceLabels: [__meta_kubernetes_pod_node_name]
          targetLabel: instance
      # -- If defined, will create a MetricsInstance for the Grafana Agent Operator.
      metricsInstance:
        # -- If enabled, MetricsInstance resources for Grafana Agent Operator are created
        enabled: true
    # Self monitoring determines whether Loki should scrape its own logs.
    # This feature currently relies on the Grafana Agent Operator being installed,
    # which is installed by default using the grafana-agent-operator sub-chart.
    # It will create custom resources for GrafanaAgent, LogsInstance, and PodLogs to configure
    # scrape configs to scrape its own logs with the labels expected by the included dashboards.
    selfMonitoring:
      enabled: true
      grafanaAgent:
        installOperator: true
    # The Loki canary pushes logs to and queries from this loki installation to test
    # that it's working correctly
    lokiCanary:
      enabled: true
      extraArgs:
        - -wait=2m0s
      tolerations:
        - effect: "NoSchedule"
          operator: "Exists"
        - effect: "NoExecute"
          operator: "Exists"  

  # Zero out replica counts of other deployment modes
  backend:
    replicas: 0
  read:
    replicas: 0
  write:
    replicas: 0
  
  ingester:
    replicas: 0
  querier:
    replicas: 0
  queryFrontend:
    replicas: 0
  queryScheduler:
    replicas: 0
  distributor:
    replicas: 0
  compactor:
    replicas: 0
  indexGateway:
    replicas: 0
  bloomCompactor:
    replicas: 0
  bloomGateway:
    replicas: 0
